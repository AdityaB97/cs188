{"start":[0,1260,4660,8940,12260,13490,14590,18570,19570,22250,25360,27560,28670,32220,35890,40980,42950,47070,50620,54450,57225,58420,61250,62720,64120,65690,66980,70830,74490,78650,79580,82870,85720,91300,94260,97150,98900,101190,102450,104500,105990,107880,111350,116330,118990,120490,125830,129740,133770,136450,140140,141840,143340,145140,148610,150530,152720,156450,159860,162250,164885,167620,169710,174760,176580,178660,179960,181920,186900,191530,193350,198180,203810,207800,211940,214660,216580,220190,221400,225540,227560,232230,233890,237240,240560,242980,245560,246360,249140,252470,256100,259250,263250,266190,269620,272150,275730,279710,283160,287540,289110,293000,295010,299760,300250,301570,302510,304930,309730,311520,313490,315150,316660,321350,323650,327710,331020,335190,337270,340700,345600,348130,353320,357600,361620,363900,369350,373770,378370,382440,385660,390360,392400,397440,401460,405160,407010,411860,414960,418160,419960,421110,425230,428010,432060,435170,437320,440910,442610,446730,448060,450140,452050,454090,456280,459180,464050,465740,469370,473120,475570],"end":[1260,4660,8940,12260,13490,14590,18570,19570,22250,25360,27560,28670,32220,35890,40980,42950,47070,50620,54450,57225,58420,61250,62720,64120,65690,66980,70830,74490,78650,79580,82870,85720,91300,94260,97150,98900,101190,102450,104500,105990,107880,111350,116330,118990,120490,125830,129740,133770,136450,140140,141840,143340,145140,148610,150530,152720,156450,159860,162250,164885,167620,169710,174760,176580,178660,179960,181920,186900,191530,193350,198180,203810,207800,211940,214660,216580,220190,221400,225540,227560,232230,233890,237240,240560,242980,245560,246360,249140,252470,256100,259250,263250,266190,269620,272150,275730,279710,283160,287540,289110,293000,295010,299760,300250,301570,302510,304930,309730,311520,313490,315150,316660,321350,323650,327710,331020,335190,337270,340700,345600,348130,353320,357600,361620,363900,369350,373770,378370,382440,385660,390360,392400,397440,401460,405160,407010,411860,414960,418160,419960,421110,425230,428010,432060,435170,437320,440910,442610,446730,448060,450140,452050,454090,456280,459180,464050,465740,469370,473120,475570,476933],"text":["","PROFESSOR: So we're going to talk about the Bellman equations.","They specify in a nice recursive way what it means to be optimal, or more","generally, what it means to compute some kind of value that we're","interested in.","And they're pretty simple.","They basically say, there's going to be one step where you actually write","out your choice.","You actually write out the Expectimax recurrence.","And then they say, once you're done with that one step, just","keep on being optimal.","What's that actually mean?","Well, for equations, that gives rise to a system of equations.","But if we think about that in terms of implementation, it suggests a kind of","recursive procedure or some kind of iterative dynamic program.","So what are these Bellman equations?","Well, we'd like to write some kind of definition of optimal utility.","And we'd like to do it via this notion of Expectimax, because that's really","what grounds our idea of what it means to act optimally.","You max when you have a choice over actions, and when things are out of","your control, you average.","And if you did that computation all the way down, that would reflect","optimal behavior.","Now of course we can't do it all the way down.","We're going to do one level.","So let's write this.","Let's write down various quantities that are going to be optimal.","And let's write it in a way that encodes what Expectimax does.","So we can first start at the top of the tree and say, the Expectimax value","of the state--","that's V* for that state.","OK, well, what did Expectimax do?","It says that the optimal value from a state is achieved by looking at all of","the actions you can take.","And you're going to take a maximum over all those actions.","Well, what are you going to maximize?","You're going to maximize the values of the children.","What are the values of the children?","Well, in Expectimax we call them chance nodes.","Now we call them Q-states.","So we can just write down their values.","Their values are Q*.","The state hasn't changed yet, because I haven't actually taken the action.","But I'm considering a specific action a.","So that's a chance node.","So the value of a state is just the max of all the chance nodes below it,","which is the max over all of the Q-states that you can get to, which is","just, we look at all the actions and then recurse into the Q-values.","Then what happens at a chance node?","How can I write an expression for the optimal value at a","Q-state or a chance node?","Well, we can think about that.","What happens in Expectimax?","We look at all of the possible outcomes, s-prime, and we take an","average over them.","So here we're going to have to take an average.","So we're going to consider all values s-prime that can occur as a result of","this action, and then we're going to take an average of those, which is","going to look like a sum.","It's going to have weights which are given by the transition function.","","And then what happens in here?","Well, here we've already committed to action a, and we're imagining that","s-prime is the outcome.","And we're going to average over all the s-primes.","Well, what happens?","Well, what happens is two things.","You immediately get an instantaneous reward.","That's the reward you get this transition, this step.","And then you land.","And when you land in s-prime, in Expectimax you would then recurse.","And the way we write that here is we just plug in V* of s-prime.","The one extra thing we had was we had a discount, which we didn't have in","vanilla Expectimax, which tells you, when you recurse, you have to multiply","in this factor of gamma so that everything lower than you in the tree","contributes less.","So here what we have is kind of mutual recurrence, if you think about this","like function calls.","But what it really is is a system of equations, because V* occurs on the","left and the right.","OK, so we have the system of equations that says optimal values are defined","in terms of optimal Q-values.","That's just the max node.","Optimal Q-values are defined in terms of optimal values of","the next state, s-prime.","It's a little more complicated, because we both have to average over","the children--","that takes more time to write out than just a max--","and because there's two components, the instantaneous reward from that","timestep and the discounted future.","Together, these are called the Bellman equations.","And they're usually written with Q inlined like this.","When you look at this, it's very easy to go into symbol shock.","But look at this, and whenever you see this, you think, oh, we're talking","about optimal values.","The optimal value of a state is like Expectimax.","I max over the action, I average over the outcomes of the","action, and then I recurse.","And what recursion means is first reward from the first timestep, and","discounted futures.","So whenever you see this, you think, oh, that's Expectimax","written one layer out.","So it's only been unrolled one layer and written as a system of equations.","OK.","These are the Bellman equations.","What do they do?","They characterize the optimal values.","They look a lot like Expectimax, and I built intuition by calling them","Expectimax-like things.","But in fact, they are not code.","They do not actually recurse.","They are a system of equations.","You plug in values, and if this system of equations holds, then that's an","optimal set of values.","These equations don't, at least on the surface, tell you how to compute the","optimal values themselves.","Now we had an algorithm that basically fixes that for us.","We have the algorithm of value iteration.","And what value iteration does is it basically just takes these Bellman","equations which characterize optimal utilities, and it turns them into a","method of computing them.","So if we think about this idea where the optimal values, V(s), are defined","in terms of other optimal values which have been unrolled one level of the","Expectimax, then we got this equation, where V* appeared on the","left and on the right.","Value iteration, which we talked about earlier, computes the values simply by","changing the equality sign into an assignment.","The critical change here was that the equations have the actual optimal","values on the left and the right, so there's no real notion of a base case.","For value iteration itself, you have to start somewhere.","And so what we had was we had a notion of time-limited, which corresponded to","depth-limited, values.","And so we had this notion of values, not the actual optimal values but the","optimal values for only k or k plus 1 more timesteps.","And so the optimal value-- that is, the score under optimal action for k","plus 1 timesteps--","has on the right-hand side optimal values for only k timesteps.","And because of this, this now is a real recursion.","It bottoms out at zero, where the optimal value for zero","timesteps is zero.","This we could implement.","And the two changes were equality became an assignment, and suddenly we","had a notion of times attached.","And as k got larger and larger, we proved that this approached the","optimal values, V*.","So what was value iteration?","Value iteration is just a fixed-point method of solving","this system of equations.","This system of equations is hard to solve, because it's got averages and","also maxes.","So it's not a linear thing.","And so we have to solve it somehow.","Value iteration is one way to do it.","Expectimax was really another way to do it.","And they have a trade-off as to which one is actually more efficient.","Now in value iteration, the vectors V sub k themselves were interpretable as","time-limited values.","But you can also view this value iteration process simply as searching","for a fixed point to these equations in an iterative way.","And that's a general way of approaching fixed-point methods.",""]}