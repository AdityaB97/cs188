{"start":[0,2090,4830,8430,11310,12240,16420,20240,22160,24740,27600,29780,32910,36510,39620,42880,47130,51550,55560,58370,62320,63860,66530,68940,71810,75170,78460,78780,82150,85760,87770,90690,95210,99270,101270,104860,107320,110180,113410,116520,117790,121140,122220,126610,130150,131660,133570,134990,137140,140400,145270,148340,151140,156550,161500,162920,164270,168410,171530,175180,179310,184720,189140,190290,194520,195550,198800,201710,205790,210180,211840,214320,215850,217200,217820,221890,223790,226310,227870,231500,234230,238000,241460,245350,246380,247485,253310,255570,257820,259070,261100,264290,265540,271040,274990,276240,280322,282130,287860,291690,297300,300230,302640,306520,307490,310260,312210,315380,317960,319210,325880,329210,331150,335230,339250,342430,344800,349180,350740,354250,357650,365850,369580,375010,385700,387010,387870,391150,393070,396680,400730,401530,403940,405940,409700,411400,413020,414600,418250,423550,426700,430880,434650,436680,439830,443190,444520,446070,449580,452350,455580,459510,463650,465270,468390,471000,474910,478050,479440,481150,482760,485010,488710,491960,495390,499100,501880,505080,506110,508970,512140,513750,517190,520490,524900,528500,531820,536880,542210,545500,547330,551630,555410,558080,562380,564780,568780],"end":[2090,4830,8430,11310,12240,16420,20240,22160,24740,27600,29780,32910,36510,39620,42880,47130,51550,55560,58370,62320,63860,66530,68940,71810,75170,78460,78780,82150,85760,87770,90690,95210,99270,101270,104860,107320,110180,113410,116520,117790,121140,122220,126610,130150,131660,133570,134990,137140,140400,145270,148340,151140,156550,161500,162920,164270,168410,171530,175180,179310,184720,189140,190290,194520,195550,198800,201710,205790,210180,211840,214320,215850,217200,217820,221890,223790,226310,227870,231500,234230,238000,241460,245350,246380,247485,253310,255570,257820,259070,261100,264290,265540,271040,274990,276240,280322,282130,287860,291690,297300,300230,302640,306520,307490,310260,312210,315380,317960,319210,325880,329210,331150,335230,339250,342430,344800,349180,350740,354250,357650,365850,369580,375010,385700,387010,387870,391150,393070,396680,400730,401530,403940,405940,409700,411400,413020,414600,418250,423550,426700,430880,434650,436680,439830,443190,444520,446070,449580,452350,455580,459510,463650,465270,468390,471000,474910,478050,479440,481150,482760,485010,488710,491960,495390,499100,501880,505080,506110,508970,512140,513750,517190,520490,524900,528500,531820,536880,542210,545500,547330,551630,555410,558080,562380,564780,568780,570667],"text":["","DAN KLEIN: Today, we'll be talking about reinforcement learning.","Reinforcement learning has a long history, including in the area of","animal reinforcement learning, for example, in psychology and behavioral","psychology.","And people have thought long and hard about what could the mechanisms be by","which, based on feedback from our actions and our environment, we learn","how to act over time.","And today, we'll talk about how we might operationalize some of these","ideas in code.","Here's the schematic for reinforcement learning.","The basic idea is you have an agent who is acting as always.","So the agent has actions available to it and chooses an action.","The environment then does what it always does, which is it resolves in","some way that's not entirely determined by the action.","For example, there may be some nondeterminism or uncertainty.","When the action resolves, what the agent receives back is two things.","One is a reward that could be kind of a bonus or a penalty, and these are","the things we want to learn to maximize over time.","The other thing the agent receives in response to its actions is a percept.","We see what happens.","So we get a state back in the simplest formulation.","Later on, we'll see how we can relax this.","But for now, we take an action which we essentially submit to the","environment by doing it, and the environment returns to us a state,","which is the result, and a reward, which we want to maximize.","We","Want to act to maximize our rewards, but of course, we have to learn to do","that, because in this setting, we won't know what actions will produce","rewards until we try them.","Because we're actually trying things in the environment, all of the","learning, all of the ways we have available to us to make good decisions","are mediated by what we experience which are samples of outcomes.","When you take an action, you see what happens.","But you don't see everything that might have happened.","So let's see some examples of what this can actually do.","This first example is from Peter Stone's group at UT Austin.","And the story here is they have these AIBOs that play soccer.","And of course, every match is in a different stadium, they go on their","world tour.","And when you're a soccer playing AIBO, at least if you're on this team, you","have this ritual.","At the beginning of every match, you go to this new stadium and you have to","learn how to walk again because the surface is a little bit different.","You get a different vibe from the crowd.","It changes everything.","So let's see what happens.","The robots are not just flailing around.","They have a gait that's programmed that allows them to walk.","But on a new surface, it initially does something like this.","It does what you think-- one leg moves and the opposite back leg moves.","And it more or less makes progress in the direction that it's trying to go.","","As this is happening, it collects information through a camera that","shows what's actually going on.","Is it making forward progress?","Is the world shaking left to right because it's unstable?","It then continues training which essentially boils down to trying","variations and learning responses based on what it's seeing.","During training, it looks a little bit like this which is better.","","They let these AIBOs walk back and forth along this new floor until this","process completes.","And when this process completes, you have this.","You have the ninja dog.","It's amazingly smooth.","And then they go and they crush their competition and all that.","In this particular case, not only do you move faster, but it's important","for how these soccer playing robots work that the camera, the vision they","have not shake around like crazy.","That makes it very hard to figure out what's going on.","You think the ball's kind of shaking through the air.","No, you're shaking.","Right?","So in addition to trying to go fast, the reward signal also should include","something about going stably.","And that's all mixed together here.","Here's another example.","People wondered how you might be able to learn to walk in a way that's","partially mediated by the structure, right?","You've been given this body that has joints in places that work for","walking, and also based on some experiences you have.","And this is Russ Tedrake's group at MIT, and here is essentially a toddler","robot learning to walk.","Let's take a look.","So at the beginning, it kind of wobbles back and forth and maybe it's","making forward-- no-- backward progress.","And maybe it should wobble a little harder.","Maybe that'll work.","","And then over time, it starts kind of moving in a not","entirely straight line.","","And then the next thing you know, it's moving purposefully around the room in","a pretty straight line.","","And before you know it, it's off to college.","","So that's a case of, again, trying various actions, seeing what's","working, improving those through interactions with the environment.","You're actually going to get a chance to do this as well which is I'm going","to show you today a crawler robot.","It's not quite as complex as these other robots, but if you squint, it's","basically there.","It's got two joints, and the goal is for it to learn to walk.","You'll build this in your project threes.","Actually, let's see an example right now.","OK, so here, what do we see?","We see a crawler robot.","","Its goal, in case you can't tell because it's kind of inept right now,","is to move to the right.","Whenever it moves to the right, it receives a reward of plus one.","Whenever it moves to the left, it receives a reward of minus one.","And its goal is to over time maximize its rewards.","So it should tend to move right over time.","Problem is, it doesn't exactly know what actions make it move right and","thereby give it rewards.","And it's trickier than you might think, because in order to move right,","you have to spend some time not moving at all as you reset your arm.","","There are some controls here I'll tell you about later.","But essentially, it's kind of figuring it out.","And if I skip a lot of time, it's going, right?","It's off to college.","OK.","So you guys will get to build that.","How was all of this done?","The framework we're going to work in is reinforcement learning.","In reinforcement learning formally, we still imagine that there is a Markov","decision process.","So just like the MDPs we've seen before.","And we already saw that in the general diagram.","We take actions and there is some state and reward that comes back, but","it's not entirely deterministic.","So it's just an MDP.","There's still a set of states.","There are still a set of actions which might depend on the state we're in.","And there's still some kind of model in principle that is determining which","state results and rewards we get back.","And there's still a reward function associated with the outcomes.","We're still trying to learn a policy which is essentially figuring out how","we should act in a given state.","The new twist in reinforcement learning and what makes this so much","harder than just solving an MDP is that we do not know","the transition function.","We don't know the rewards.","And that is even though based on my state and my action, there's a certain","set of outcomes with a certain probability distribution.","I don't know which probability distribution it is.","And so the only way to really know what our actions do and where the","rewards come from is to try things out, and then learn from our samples","that we experience.","Now, of course, because we're trying things out from a state of partial","information, we're going to make some mistakes.","And so there is always going to be this process of trying things out not","all of which work optimally.","So here's an MDP.","This is, again, the race car.","You see the three states of the race car.","And if I gave you this MDP, you could just solve it.","You could value iteration or expectimax for that matter.","If you were going to reinforcement learn how to be this car that tries","not to overeat, the difference would be you still know whether you're cool,","warm, or overheated, and you still know that you can move fast or slow.","What you don't know is what fast and slow do.","So for all you know, fast is the best idea ever, or slow is","the best idea ever.","You try some things, maybe you end up going too slow or maybe you overheat.","And you have to try things again and slowly learn what these actions do","from each state.","A critical difference, now that we're thinking about reinforcement learning,","is the difference between what we're doing now and what we were doing in","the last unit on solving Markov decision processes, especially since","even in reinforcement learning, there are still all of these MDP-like things","like rewards and so on.","Offline solution is when you know what your actions will do, and in","computation, in simulation, in your head, you think about consequences,","whether that's via an expectimax style search or a dynamic","program like value iteration.","You realize that jumping into the pit is a bad idea because you know it has","a negative reward, and so you never actually do it.","That's offline solution.","When you're doing online learning, you have to actually jump into the pit","before you know it is bad.","You might imagine that over time, this increases the cost of the robots.",""]}