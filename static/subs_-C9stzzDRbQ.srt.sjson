{"start":[0,890,3720,6870,9200,10250,11100,13580,17440,18530,22150,26020,28900,32000,34200,34580,38400,39270,40550,44000,49310,50570,54800,56670,58550,61410,63440,65239,69390,71570,75640,79590,82810,85150,87560,91660,95390,98330,100660,103340,105640,109640,112140,114590,118260,121470,124100,126000,129729,132790,133440,137040,138600,141330,142320,146240,148200,150280,154650,158590,159700,160710,161840,163750,165980,168940,171950,175600,179720,181190,183290,186040,188690,189680,194330,195630,199230,202950,206200,210760,211500,213040,214890,216450,217780,221910,224830,228040,231330,233800,235690,238530,240590,241540,242430,243750,246210,249360,253080,253880,256540,257300,259050,259260,261899,262530,263820,266550,269900,271100,272810,274810,276550,278480,282400,283600,287790,292570,297480,298930,301460,302340,305670,308860,312060,313990,316730,318020,318440,320020,322700,325400,326670,329850,335170,338010,339230,342270,346730,348850,352280,356030,357700,361840,365050,367050,368805,369710,372190,373480,374900,378120,381410,385760,388390,389630,393000,395660,398280,400110,403430,405990,409260,410580,413530,415470,418170,420900,421760,422660,424610,425520,429260,431850,432840,434920,438170,439260,441610,441910,444310,446630,450880,455100,456550,458490],"end":[890,3720,6870,9200,10250,11100,13580,17440,18530,22150,26020,28900,32000,34200,34580,38400,39270,40550,44000,49310,50570,54800,56670,58550,61410,63440,65239,69390,71570,75640,79590,82810,85150,87560,91660,95390,98330,100660,103340,105640,109640,112140,114590,118260,121470,124100,126000,129729,132790,133440,137040,138600,141330,142320,146240,148200,150280,154650,158590,159700,160710,161840,163750,165980,168940,171950,175600,179720,181190,183290,186040,188690,189680,194330,195630,199230,202950,206200,210760,211500,213040,214890,216450,217780,221910,224830,228040,231330,233800,235690,238530,240590,241540,242430,243750,246210,249360,253080,253880,256540,257300,259050,259260,261899,262530,263820,266550,269900,271100,272810,274810,276550,278480,282400,283600,287790,292570,297480,298930,301460,302340,305670,308860,312060,313990,316730,318020,318440,320020,322700,325400,326670,329850,335170,338010,339230,342270,346730,348850,352280,356030,357700,361840,365050,367050,368805,369710,372190,373480,374900,378120,381410,385760,388390,389630,393000,395660,398280,400110,403430,405990,409260,410580,413530,415470,418170,420900,421760,422660,424610,425520,429260,431850,432840,434920,438170,439260,441610,441910,444310,446630,450880,455100,456550,458490,459900],"text":["","PROFESSOR: Everything in minimax and expectimax search has made reference","to the idea that there are utilities that you can go around, either","maximizing or taking averages of.","What are these numbers?","Where do they come from?","And how do we know they even exist?","If we had numbers that represented our preferences, why are we","even averaging them?","So before we compute what these utilities are, why did we ever talk","about anything other than minimax I mean, after all, we understand minimax","pretty well, and it gives us some pretty good worst case bounds.","Why don't we always run around doing minimax search?","The answer is vampire bunnies.","Right?","There are things that your model might imagine but have such small","probability.","But they're really bad.","And maybe you don't worry so much about vampire bunnies, but you imagine","things like well, should I go to eat Thai food or should I go to eat","Italian food?","Well, if I go to eat Thai food, it might be a little too spicy.","I might get hit by a meteor.","STUDENTS: [LAUGHTER].","PROFESSOR: And then you think about in the Italian food, well, let's see, it","might be very greasy.","Or I might get hit by a meteor.","And you go around and all of your computations are dominated by these","events which are very bad and very unlikely.","Worst case reasoning only works to the extent that your model is sufficiently","simple, that the really bad, really rare stuff isn't even considered.","If you want to be robust to the fact that bad things can happen but usually","don't, you need average case reasoning.","You really have no choice.","And what that leads us to is the principle of maximum expected utility.","This principle states that a rational agent should choose the action that","maximizes its expected utility given its knowledge.","We've already seen a lot of this definition.","We already know what it means to take the best choice, to maximize.","We've seen a lot of that kind of [? tree-search. ?]","We now know what expectations are and what expectimax is.","And that really tells you about expected utilities.","And for the rest of the course, we're going to spend a lot of energy","unpacking this idea of what is the expectation, given our knowledge?","And that's going to lead us to probabilistic inference.","So that's the principle of maximum expected utility.","But where do these utilities come from?","How do we know there are utilities that represent our preferences at all?","How do we know that averaging even makes sense?","Right?","Maybe you don't think that averaging these numbers actually still preserves","your preferences.","What if our behavior is so complex and subtle?","We're humans, right?","Our behavior is so complex and subtle, we cannot possibly be reduced to a","real valued function.","So what are these utilities?","Utilities are functions from outcomes, which are states of the world, to real","numbers that encode an agent's preferences.","Where do these come from?","Well, in a game, it's easy.","It's part of the definition.","Plus one if you win, minus one if you lose.","Your score, whatever it is.","The utilities have to summarize the agent's goals.","And there's a theorem that says if your preferences are basically","reasonable, they can be summarized by a utility function.","In general, the approach we take with utilities is to think of the utilities","as the input--","we hard-wire utilities--","and the behavior, the action selection, as the output.","The behaviors emerge through computation.","And why do we want this?","Why do we want the goals to be the input and the optimal behavior to be","the output of the computation?","Why don't we just let agents pick their own utilities?","What would happen if we let a vacuum cleaner agent pick its own utility?","And it wanted to then maximize that utility?","It sits, and it thinks and it thinks ah, I would like to do nothing.","Right?","And it's so easy to do nothing.","And now it's happy because it picked its utility.","And it's so happy with its utility.","But it's not what we wanted.","What we say is no, your utility is picking up dirt.","And now the vacuum cleaner does whatever it does to maximize that.","We don't want to dictate the behavior, because we don't want to get into like","drawing the particular pattern it should trace out on the floor.","The search procedure should do all that for us.","So we don't want to prescribe the behavior.","It's very hard to write down behavior, because behavior is complicated and","context-dependent.","So that's the idea.","Utilities go in.","Behavior comes out.","Now we got to be careful about this, because if you just tell the vacuum","cleaner your goal is to pick up dirt, maybe it gets this idea that the best","way to pick up dirt is to pick up dirt, dump the dirt, pick it up again,","and dump it again.","And so you need to make sure when you encode these things, you actually mean","what you say.","But you know, that's your problem.","Right?","The vacuum cleaner's just doing what you told it to do.","All right.","So, utilities.","Let's imagine we have an ice cream eating robot.","And it looks at these various outcomes and it says well, you know an ice","cream cone is good.","It's better if it has a scoop in it.","And two scoops is great.","So over these outcomes--","zero, one, or two scoops--","maybe we agree that a reasonable ice cream cone robot might order","them in this way.","That one is better than zero, and two is better than one.","However, we're actually going to ask the robot, in reality, to make","decisions not just amongst number of scoops, which is easy, but amongst","uncertain outcomes.","So, for example, you imagine the robot has a choice.","It's getting ice cream.","And it can order a single scoop or it could order a double scoop.","And if it orders a single scoop, well, it ends up with a single scoop of ice","cream, which we decided was kind of in the middle.","What happens if it orders a double scoop?","Well, the problem with ordering a double scoop is that's a lot of ice","cream piled high.","Right?","Something bad could happen.","You know, oops, your ice cream is on the floor, and you have no scoops.","But most of the time, everything's fine, and you get to","enjoy your yummy scoops.","The agent is going to have to have a preference between these two outcomes.","Does it prefer the guaranteed single scoop or does it prefer this uncertain","mix of zero or two?","Well, it's actually OK.","Different utilities are going to make different choices here, but the point","is the agent's preferences need to encode whether or not it would choose","single or double in this case.","And the specific numbers we assign are going to make that determination when","we run an expectimax search.","So what are these preferences?","Well, an agent has to have preferences among various things.","We know, for example, zero, one, and two ice cream scoops--","it has to have preferences amongst what are called","prizes, specific outcomes.","They're called prizes.","They don't have to be wrapped up as a present or anything like that.","That's just the technical term.","A prize is a specific outcome.","So you have A and B which might be various numbers of scoops.","We have to have preference among the prizes, but we also have to be able to","order our preferences amongst lotteries, which are situations where","you're not sure which prize you're going to get.","And that's shown here.","So you have prizes, which are atomic outcomes, and you have lotteries,","which are mixtures with a certain probability.","And if you look at that, you think that's exactly what a chance note is.","It creates a little lottery.","And an expectimax tree is really just a bigger cursive lottery.","So these lotteries and these prizes--","we have to have preferences, meaning, an agent has to","prefer one or the other.","And the question is just are there utilities that reflect those","preferences?","So when I say lottery, there are real lotteries.","There are real lotteries where you pay your money.","You get your ticket.","You scratch it off.","And you hope it's the right number.","Right?","When we say lottery here, we do not mean the actual act of","gambling in a lottery.","That's fine.","But that introduces a lot of complexity.","For example, when you actually play the lottery, sometimes you win and","sometimes you lose.","But win or lose, you played.","Right?","And that's important, because part of the reason why people play lotteries","is they like to play lotteries.","When we say lottery here, and we say 50% chance of A and 50% chance of B,","we do not mean \"and the fun of playing.\" We simply mean you are not","sure which one's going to happen.","For example, rolling the dice in a sense is a lottery.",""]}